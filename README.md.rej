diff a/README.md b/README.md	(rejected hunks)
@@ -123,29 +123,40 @@ python scripts/run_pipeline.py --region hungary_farmland --refresh
 # Day-to-day analysis (offline)
 python scripts/run_pipeline.py --region hungary_farmland --analyze --allow-stale
 ```
 
 ### Pipeline modes & data layout
 
 - `--bootstrap` performs the first end-to-end fetch for a region, materialising every required layer into `data/<region>/caches/<timestamp>` and promoting it to `data/<region>/current/`.
 - `--refresh` only re-fetches layers whose TTL has expired, creating a new dated snapshot before updating `current/` atomically.
 - `--analyze` never touches the network. It validates cache freshness (respecting `--allow-stale` and `--max-staleness`) and rebuilds insights from the data stored under `data/<region>/current/`.
 - Each snapshot writes a provenance manifest (`manifest.json`) capturing fetch metadata, hashes, TTL policies, and expiry timestamps.
 
 ### CI guardrails
 
 - `.github/workflows/test-run.yml` runs `--analyze --allow-stale` on every push to guarantee the repository stays runnable offline.
 - `.github/workflows/monthly-refresh.yml` opens a scheduled online window on the first of each month to refresh caches, upload manifests, and push the updated `data/<region>/current/` view.
 ### üöÄ Run the end-to-end pipeline
 
 You can run the full regional workflow (initialization ‚Üí fetch ‚Üí cache ‚Üí insights ‚Üí model training) with a single command:
 
 ```bash
 python scripts/run_pipeline.py --region hungary_farmland
 ```
 
 Add flags such as `--skip-fetch`, `--skip-train`, or `--report reports/hungary_pipeline.json` to customize what runs and to capture a machine-readable summary of each stage.
 
+### Region metadata utilities
+
+Reusable helpers for storing and enriching region metadata live in `engine/utils/metadata.py`. The module exposes `load_region_metadata` for loading profiles during the insight pipeline as well as `update_metadata`, which writes incremental metadata snapshots to each region cache (useful for future mesh association research or curating new training corpora).
+
 > ‚ÑπÔ∏è The pipeline automatically calls `scripts/init_region.py` for you. Keep `init_region` handy for manual setup or tweaking metadata, but use `run_pipeline` when you want the full orchestration in one go.
 
 Recommended Python: 3.12.x
-Compatible with: Kaggle notebooks and GitHub Actions CPU runners
+Validated on local development machines and GitHub Actions CPU runners
+
+### Model checkpoints
+
+Pre-trained Random Forest binaries are **not** tracked in the repository to keep the tree
+source-only. When `engine.model_predict.predict_outcomes` runs, it will load a cached
+checkpoint if one exists under `models/<region>_rf.pkl`; otherwise it trains a fresh,
+lightweight model on the distilled features and persists it locally for future runs.diff --git a/agent/__init__.py b/agent/__init__.py
